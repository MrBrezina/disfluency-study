{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and evaluate raw data\n",
    "\n",
    "Basic processing to convert data from its raw form\n",
    "returned by the website to a format useful for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set up a DataFrame to collect the processed data\n",
    "columns = [\n",
    "    \"StudyID\", \"ParticipantID\", \"Fluent\", \"Training\",\n",
    "    \"TestID\", \"Type\", \"TrialID\",\n",
    "    \"Font\", \"Sample\", \"Category\",\n",
    "    \"Response\", \"Correct\", \"Seen\", \"Foil\", \"RT\", \"RTnorm\",\n",
    "    \"JoM\", \"JoL\", \"Date\",\n",
    "]\n",
    "d = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data from the raw format to stats-ready format\n",
    "\n",
    "The raw format has all responses from one participant in a single row\n",
    "this breaks down results for individual trials (saved in columns like “test_1_lexical”)\n",
    "and saves these as individual rows.\n",
    "\n",
    "Deal with some minor format differences as the formatting evolved with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15768 responses from 219 participants.\n"
     ]
    }
   ],
   "source": [
    "# Warning: this takes quite a while to compute\n",
    "\n",
    "# participant counter (Participant ID)\n",
    "pid = 0\n",
    "# counter for trials within each session of a single participant\n",
    "x = 0\n",
    "for fn in glob.glob(\"data__*.csv\"):\n",
    "    raw = pd.read_csv(fn)\n",
    "    for i, rraw in raw.iterrows():\n",
    "        # collect data that will be shared across all rows\n",
    "        # for one participant\n",
    "        shared = pd.Series(index=d.columns, dtype=\"float64\")\n",
    "        if \"studyid\" in rraw:\n",
    "            shared[\"StudyID\"] = rraw[\"studyid\"]\n",
    "        else:\n",
    "            shared[\"StudyID\"] = 0  # pilot study\n",
    "        shared[\"ParticipantID\"] = pid\n",
    "        if \"Fluent\" in rraw:\n",
    "            shared[\"Fluent\"] = rraw[\"Fluent\"]\n",
    "        # deal with legacy column names\n",
    "        if \"Native\" in rraw:\n",
    "            shared[\"Fluent\"] = rraw[\"Native\"]\n",
    "        if \"Designer\" in rraw:\n",
    "            shared[\"Training\"] = rraw[\"Designer\"]\n",
    "        if \"Design_skills\" in rraw:\n",
    "            shared[\"Training\"] = rraw[\"Design_skills\"]\n",
    "        for c in rraw.index:\n",
    "            # get values from columns like this: test_1_lexical_5\n",
    "            # ignore values from columns like this: test_1_remember\n",
    "            # or test_1_legibility\n",
    "            if c.startswith(\"test_\") and \\\n",
    "               not (c.endswith(\"_remember\") or c.endswith(\"_legibility\")):\n",
    "                # prefill with shared data\n",
    "                rd = pd.Series(shared)\n",
    "                # set defaults\n",
    "                rd[\"Category\"], rd[\"Seen\"], rd[\"Foil\"] = np.nan, np.nan, np.nan\n",
    "                # get Test ID, Type, and Trial ID from the column name\n",
    "                _, rd[\"TestID\"], rd[\"Type\"], rd[\"TrialID\"] = c.strip().split(\"_\")\n",
    "                # get respond from the value in this column\n",
    "                response = rraw[c].strip().split(\",\")\n",
    "                # tackle legacy formats of responses\n",
    "                # when only some values were provided\n",
    "                rd[\"Font\"] = response[0].strip()\n",
    "                rd[\"Response\"] = response[-2].strip()\n",
    "                rd[\"RT\"] = float(response[-1].strip())\n",
    "                if rd[\"Type\"] == \"lexical\":\n",
    "                    if len(response) == 4:\n",
    "                        rd[\"Sample\"] = response[1].strip()\n",
    "                    else:\n",
    "                        rd[\"Category\"] = response[1].strip()\n",
    "                        rd[\"Sample\"] = response[2].strip()\n",
    "                else:\n",
    "                    if len(response) == 5:\n",
    "                        rd[\"Sample\"] = response[1].strip()\n",
    "                        rd[\"Seen\"] = response[2].strip()\n",
    "                    elif len(response) == 6:\n",
    "                        rd[\"Category\"] = response[1].strip()\n",
    "                        rd[\"Sample\"] = response[2].strip()\n",
    "                        rd[\"Seen\"] = response[3].strip()\n",
    "                    else:\n",
    "                        rd[\"Category\"] = response[1].strip()\n",
    "                        rd[\"Sample\"] = response[2].strip()\n",
    "                        rd[\"Seen\"] = response[3].strip()\n",
    "                        rd[\"Foil\"] = response[4].strip()\n",
    "                # fix legacy values\n",
    "                if isinstance(rd[\"Category\"], str):\n",
    "                    rd[\"Category\"] = rd[\"Category\"].replace(\"nonword\", \"non-word\")\n",
    "                if isinstance(rd[\"Seen\"], str):\n",
    "                    rd[\"Seen\"] = rd[\"Seen\"].replace(\"non-seen\", \"not seen\")\n",
    "                rd[\"Response\"] = rd[\"Response\"].replace(\"non-seen\", \"not seen\")\n",
    "                # add the judgement of learning for this part\n",
    "                # value from column test_1_remember\n",
    "                rd[\"JoM\"] = rraw[\"test_%s_remember\" % rd[\"TestID\"]]\n",
    "                # add the judgement of legibility for this part\n",
    "                # value from column test_1_legibility\n",
    "                rd[\"JoL\"] = rraw[\"test_%s_legibility\" % rd[\"TestID\"]]\n",
    "                rd[\"Date\"] = rraw[-1]\n",
    "                # add a row with for individual trial\n",
    "                d.loc[x] = rd\n",
    "                x += 1\n",
    "        pid += 1\n",
    "# fix types\n",
    "d[\"StudyID\"] = d[\"StudyID\"].astype(int)\n",
    "d[\"ParticipantID\"] = d[\"ParticipantID\"].astype(int)\n",
    "# add normalized RT\n",
    "d[\"RTnorm\"] = np.log(d[\"RT\"])\n",
    "\n",
    "print(\"Processed %d responses from %d participants.\" % (len(d), pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing data & evaluate responses\n",
    "\n",
    "Also add response time (RT) transformed using natural logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: this takes quite a while to compute\n",
    "\n",
    "# get a list of words and non-words from txt files used for the website\n",
    "# and map them to their category names (word, non-word)\n",
    "categories = {}\n",
    "for cat in [\"words\", \"non-words\"]:\n",
    "    with open(cat + \".txt\") as f:\n",
    "        for w in f.readlines():\n",
    "            categories[w.strip()] = cat[:-1] # remove the final \"s\"\n",
    "\n",
    "# add missing data & evaluate responses\n",
    "for i, rd in d.iterrows():\n",
    "    # convert string \"yes\" to boolean\n",
    "    rd[\"Fluent\"] = (rd[\"Fluent\"] == \"yes\")\n",
    "    if isinstance(rd[\"Category\"], float) or rd[\"Category\"] is np.nan:\n",
    "        # assing correct category if missing\n",
    "        rd[\"Category\"] = categories[rd[\"Sample\"]]\n",
    "    # set Correct to 1 when the participant said sure or probably\n",
    "    # set to zero otherwise\n",
    "    rd[\"Correct\"] = 0\n",
    "    if rd[\"Type\"] == \"lexical\":\n",
    "        if rd[\"Response\"] == (\"Sure \" + rd[\"Category\"]) or \\\n",
    "          rd[\"Response\"] == (\"Probably \" + rd[\"Category\"]):\n",
    "            rd[\"Correct\"] = 1\n",
    "    elif rd[\"Type\"] == \"recognition\":\n",
    "        if rd[\"Response\"] == (\"Sure \" + rd[\"Seen\"]) or \\\n",
    "          rd[\"Response\"] == (\"Probably \" + rd[\"Seen\"]):\n",
    "            rd[\"Correct\"] = 1\n",
    "    d.loc[i] = rd\n",
    "            \n",
    "# add normalized RT\n",
    "d[\"RTnorm\"] = np.log(d[\"RT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to a CSV file.\n"
     ]
    }
   ],
   "source": [
    "# save the processed data\n",
    "d.to_csv(\"data_processed.csv\")\n",
    "print(\"Successfully saved to a CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
